{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wgan_capcha.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"VQV8aGkPnFIs","colab_type":"code","outputId":"acd8f0fe-2b7b-4d8a-ed0a-67dba145edcf","executionInfo":{"status":"ok","timestamp":1543257145168,"user_tz":300,"elapsed":7022,"user":{"displayName":"Li Jingyao","photoUrl":"","userId":"00014143790950746268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["!ls\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":4,"outputs":[{"output_type":"stream","text":["adc.json  sample_data\n"],"name":"stdout"}]},{"metadata":{"id":"OylMrQ9enTyl","colab_type":"code","outputId":"a774a82a-5792-4f15-9591-5a900f772102","executionInfo":{"status":"ok","timestamp":1543257132956,"user_tz":300,"elapsed":56738,"user":{"displayName":"Li Jingyao","photoUrl":"","userId":"00014143790950746268"}},"colab":{"base_uri":"https://localhost:8080/","height":574}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package libkmod2:amd64.\n","(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 22298 files and directories currently installed.)\n","Preparing to unpack .../libkmod2_24-1ubuntu3.1_amd64.deb ...\n","Unpacking libkmod2:amd64 (24-1ubuntu3.1) ...\n","Selecting previously unselected package kmod.\n","Preparing to unpack .../kmod_24-1ubuntu3.1_amd64.deb ...\n","Unpacking kmod (24-1ubuntu3.1) ...\n","Selecting previously unselected package module-init-tools.\n","Preparing to unpack .../module-init-tools_24-1ubuntu3.1_all.deb ...\n","Unpacking module-init-tools (24-1ubuntu3.1) ...\n","Setting up libkmod2:amd64 (24-1ubuntu3.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","Setting up kmod (24-1ubuntu3.1) ...\n","Setting up module-init-tools (24-1ubuntu3.1) ...\n","Selecting previously unselected package libfuse2:amd64.\n","(Reading database ... 22345 files and directories currently installed.)\n","Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package fuse.\n","Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking fuse (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package google-drive-ocamlfuse.\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu2~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu2~ubuntu18.04.1) ...\n","Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","Setting up fuse (2.9.7-1ubuntu1) ...\n","Setting up google-drive-ocamlfuse (0.7.1-0ubuntu2~ubuntu18.04.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"lGcRCBiqoQ-Q","colab_type":"code","colab":{}},"cell_type":"code","source":["class pic(): # Define a Class to do some pre operations of images \n","  def __init__(self, filename):\n","    self.filename = filename;\n","    self.width = 120 # image width\n","    self.height = 48 # image height\n","    self.name_list, self.file_list = self.untar(self.filename)\n","    self.data_set = self.getdataset(self.file_list)\n","  \n","  def untar(self, filename): # uncompress the tar.gz file\n","    name_list = []\n","    file_list = []\n","    with tarfile.open(filename, \"r\") as file:\n","        for i in file.getmembers(): # use tar file module to untar the file\n","            f = file.extractfile(i)\n","            if f is not None:\n","              content = f.read()\n","              name_list.append(i.name)\n","              file_list.append(content)\n","    \n","    return name_list, file_list # return the file name list and file list\n","\n","  def getdataset(self, file_list): # get data_set with np.array format\n","    data_set = []\n","    for i in range(len(file_list)):\n","      try:\n","        im = Image.open(BytesIO(file_list[i]))  # file_list is the binary stream, that needs to transfer to image format\n","      except OSError:\n","        pass\n","      im = im.convert(\"L\") # convert images to gray scale\n","      data = im.getdata()  # get image tuple\n","      data = np.matrix(data)  # turn the image tuple to matrix\n","      \n","      try:\n","        picture = np.reshape(data,(self.height, self.width))  # turn to numpy array\n","      except ValueError:\n","        pass\n","      left, right = self.splitpic(picture) # split the image to enlarge the data_set\n","      data_set.append(left)\n","      data_set.append(right)\n","    return np.array(data_set)\n","\n","  def showim(self,picture): # show image\n","    plt.imshow(picture)\n","    plt.show()\n","\n","  def splitpic(self,picture): # split the image\n","    return np.split(picture, 2, axis=1)[0], np.split(picture, 2, axis=1)[1]\n","  \n","  def gendataset(self): # return the data_set\n","    return self.data_set"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0de4SbaSomeK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5a16f6eb-8e08-4f7d-b913-c6f98769c3e1","executionInfo":{"status":"ok","timestamp":1543257168565,"user_tz":300,"elapsed":2062,"user":{"displayName":"Li Jingyao","photoUrl":"","userId":"00014143790950746268"}}},"cell_type":"code","source":["from __future__ import print_function, division\n","import tarfile\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from io import BytesIO\n","import cv2\n","from PIL import Image\n","\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n","from keras.models import Sequential, Model\n","from keras.optimizers import RMSprop\n","import matplotlib.pyplot as plt\n","import keras.backend as K"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"by2IRjWaoqFb","colab_type":"code","colab":{}},"cell_type":"code","source":["class WGAN():\n","    def __init__(self):\n","        self.img_height = 48\n","        self.img_width = 60\n","        self.channels = 1\n","        self.img_shape = (self.img_height, self.img_width, self.channels)\n","        self.latent_dim = 100\n","    \n","        # Following parameter and optimizer set as recommended in paper\n","        self.n_critic = 5\n","        self.clip_value = 0.01\n","        optimizer = RMSprop(lr=0.00005)\n","\n","        # Build and compile the critic\n","        self.critic = self.build_critic()\n","        self.critic.compile(loss=self.wasserstein_loss, optimizer=optimizer, metrics=['accuracy'])\n","        \n","        # Build the generator\n","        self.generator = self.build_generator()\n","        \n","        # Noise as input\n","        z = Input(shape=(self.latent_dim,))\n","        img = self.generator(z)\n","        \n","        # For the combined model we will only train the generator\n","        self.critic.trainable = False\n","        \n","        # The critic takes generated images as input and determines validity\n","        valid = self.critic(img)\n","        \n","        # The combined model  (stacked generator and critic)\n","        self.combined = Model(z, valid)\n","        self.combined.compile(loss=self.wasserstein_loss,\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","        \n","    def wasserstein_loss(self, y_true, y_pred):\n","        return K.mean(y_true * y_pred)\n","    \n","    def build_generator(self):\n","      \n","        moment = 0.5\n","        model = Sequential()\n","        \n","        model.add(Dense(1024 * 12 * 15, activation=\"relu\", input_dim=self.latent_dim))\n","        model.add(BatchNormalization(momentum=moment))\n","        model.add(Activation(\"relu\"))\n","        model.add(Reshape((12, 15, 1024)))\n","        \n","        model.add(Conv2DTranspose(512, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=moment))\n","        model.add(Activation(\"relu\"))\n","        \n","        model.add(Conv2DTranspose(256, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=moment))\n","        model.add(Activation('relu'))\n","        \n","        model.add(Conv2DTranspose(128, kernel_size=3, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=moment))\n","        model.add(Activation('relu'))\n","        \n","        model.add(Conv2DTranspose(64, kernel_size=3, padding='same'))\n","        model.add(BatchNormalization(momentum=moment))\n","        model.add(Activation('relu'))\n","        \n","        model.add(Conv2DTranspose(32, kernel_size=3, padding='same'))\n","        model.add(BatchNormalization(momentum=moment))\n","        model.add(Activation('relu'))\n","        \n","        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n","        model.add(Activation(\"tanh\"))\n","        \n","        model.summary()\n","        \n","        noise = Input(shape=(self.latent_dim,))\n","        img = model(noise)\n","\n","        return Model(noise, img)\n","      \n","    def build_critic(self):\n","        dropout = 0.3\n","        \n","        model = Sequential()\n","\n","        model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(dropout))\n","        \n","        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(dropout))\n","        \n","        model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(dropout))\n","        \n","        model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(dropout))\n","        \n","        model.add(Flatten())\n","        model.add(Dense(1, activation='sigmoid'))\n","        \n","        model.summary()\n","        img = Input(shape=self.img_shape)\n","        validity = model(img)\n","        return Model(img, validity)\n","      \n","    def train(self, epochs, data_set, batch_size=128, sample_interval=50):\n","        data_set = data_set / 127.5 - 1. # Rescale -1 to 1\n","        data_set = np.expand_dims(data_set, axis=3)\n","        \n","        # Adversarial ground truths\n","        valid = -np.ones((batch_size, 1))\n","        fake = np.ones((batch_size, 1))\n","        \n","        for epoch in range(epochs):\n","            for _ in range(self.n_critic):\n","                # Select a random batch of images\n","                idx = np.random.randint(0, data_set.shape[0], batch_size)\n","                imgs = data_set[idx]\n","                \n","                # Sample noise as generator input\n","                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","                \n","                # Generate a batch of new images\n","                gen_imgs = self.generator.predict(noise)\n","                \n","                # Train the critic\n","                d_loss_real = self.critic.train_on_batch(imgs, valid)\n","                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n","                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n","                \n","                # Clip critic weights\n","                for l in self.critic.layers:\n","                    weights = l.get_weights()\n","                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n","                    l.set_weights(weights)\n","                    \n","            g_loss = self.combined.train_on_batch(noise, valid)\n","            \n","            # Plot the progress\n","            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n","                \n","            # If at save interval => save generated image samples\n","            if epoch % sample_interval == 0:\n","                self.sample_images(epoch)    \n","                \n","    def sample_images(self, epoch):\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 1\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","                axs[i,j].axis('off')\n","                cnt += 1\n","#         fig.savefig(\"images/mnist_%d.png\" % epoch)\n","        plt.show()\n","        plt.close()\n","    \n","    def dataset(self, data_set):\n","      data_set = self.getdataset(file_list, 48, 120)\n","      return data_set"],"execution_count":0,"outputs":[]},{"metadata":{"id":"21s-Gowmv1si","colab_type":"code","outputId":"e02691c0-097e-42fe-e690-ebdc75333476","executionInfo":{"status":"error","timestamp":1543265406840,"user_tz":300,"elapsed":635,"user":{"displayName":"Li Jingyao","photoUrl":"","userId":"00014143790950746268"}},"colab":{"base_uri":"https://localhost:8080/","height":229}},"cell_type":"code","source":["if __name__ == '__main__':\n","    pic1 = pic('drive/colab/yzm1.tar.gz')\n","    data_set1 = pic1.gendataset()\n","    pic2 = pic('drive/colab/yzm.tar.gz')\n","    data_set2 = pic2.gendataset()\n","    data_set = np.concatenate((data_set1, data_set2), axis = 0)\n","    wgan = WGAN()\n","    wgan.train(epochs=20000, batch_size=32, sample_interval=50, data_set = data_set)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6a3b1ae0310e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpic1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/colab/yzm1.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata_set1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgendataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpic2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/colab/yzm.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata_set2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgendataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pic' is not defined"]}]}]}